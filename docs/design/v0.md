# v0

**Table of contents**


<!-- @import "[TOC]" {cmd="toc" depthFrom=2 depthTo=6 orderedList=false} -->
<!-- code_chunk_output -->

* [Software to solve problems aka "Evaluate all them software"](#software-to-solve-problems-aka-evaluate-all-them-software)
* [Environment Assumptions](#environment-assumptions)
* [Goals](#goals)
* [Flows](#flows)
	* [Initial start and Failover](#initial-start-and-failover)
	* [Run](#run)
* [Templating](#templating)
	* [Variables](#variables)
* [File Structure](#file-structure)
	* [Variables](#variables-1)
		* ["Base" File](#base-file)
		* [Variable File](#variable-file)
		* ["From Host" Variable File](#from-host-variable-file)
	* [Custom Functions](#custom-functions)
		* ["Base" Custom Functions File](#base-custom-functions-file)
		* [Custom Functions File](#custom-functions-file)
	* [Jobs](#jobs)
	* [Tasks](#tasks)
		* [Example: Dependencies](#example-dependencies)
		* [Example: Orchestrated sharing of data betweem nodes](#example-orchestrated-sharing-of-data-betweem-nodes)
	* [Events](#events)
		* ["Base" Custom Events File](#base-custom-events-file)
		* [Custom Events File](#custom-events-file)
	* [Events Reaction](#events-reaction)

<!-- /code_chunk_output -->

## Software to solve problems aka "Evaluate all them software"

Aka list of software and/or decisions to be evaluated/made.

- [ ] Detect software/node failures
    - [ ] Custom implementation (using HTTP; "based" on [hashicorp/memberlist](https://github.com/hashicorp/memberlist))
- [x] Key Value store
    - [x] [coreos/etcd](https://github.com/coreos/etcd)
- [x] Event distribution
    - [x] [coreos/etcd](https://github.com/coreos/etcd)
- [ ] Modules
    - [ ] File handling
    - [ ] Package handling
        - [ ] PackageKit
        - [ ] Alternatives?
    - [ ] Command Executor
        - [ ] Golang native lib

## Environment Assumptions

These are the assumptions of the general environment where one would use this project/tool.

* (Always) at least 3 or more servers.
* All user given "state" code is in one or more git repositories.
* Network is "unsecure"/public/untrusted.
    * Connections to servers using SSH are considered secure.

## Goals

* If a node fails which is currently a datastore, the cluster can continue to work.
    * An existing node that is eligible to be a datastore will take over the datastore role.
* Running a "state" allows another "state" to use it and/or it's output as a variable.
* `require` and `require_in` and so on from Saltstack are correctly identified and applied to the ordering.
    * NOTE: There will be different ordering modes, e.g.:
        - "justdoit" mode which does not do any ordering (except `require`, etc are respected) and just fires all others at once.
        - "ansible" mode which does execute one task after another, respecting `require`, etc.
        - `genius` mode which does "complex" ordering and optimization (e.g., add a repo first and then run `dnf update`).
            - **Will probably not be a thing in the _zero_ (first) version**
* There are some simple default modules.
    * Planned:
        * `cmd`
    * Future:
        * `pkg` (PackageKit ?)
        * `pkgrepo` (PackageKit ?)
* Extension modules can be copied from the datastore or an "external" source, and be verified.

## Flows
### Initial start and Failover

![v0/flow-init_and_failover.mmd rendered](v0/flow-init_and_failover.mmd.png)

See [v0/flow-init_and_failover.mmd](v0/flow-init_and_failover.mmd) for source code of diagram.

### Run

![v0/flow-run.mmd rendered](v0/flow-run.mmd.png)

See [v0/flow-run.mmd](v0/flow-run.mmd) for source code of diagram.

## Templating

### Variables

| Name        | Description              |
| ----------- | ------------------------ |
| `functions` | All available functions. |

## File Structure

### Variables

#### "Base" File

```yaml
files:
  '*':
    - name: common
    - name: network/{host}.yaml
      required: false
```

#### Variable File

```yaml
sysctl:
  fs.file-max: 2097152
  net.ipv4.ip_local_port_range: "8192 65535"

my_variable: true
```

#### "From Host" Variable File

**NOTE** These files are read by the edenconfmgmt daemon during start.

```yaml
network:
  defaultInterface: eth1
```

### Custom Functions

#### "Base" Custom Functions File

```yaml
functions:
  '*':
    - name: uptime
  'role=kubernetes-*':
    - name: kubeadm/kubernetes
```

#### Custom Functions File

```yaml
uptime:
  # `file.contents` would be better here
  cmd.run:
    - cmd: cat /proc/uptime

kubernetes_cluster_master_count:
  template.expression:
    - content: |
      {{ eden['servers_get_by_label']('kubernetes.io/kubeadm-master=') | length }}
```

### Jobs

```yaml
jobs:
  '*':
    - name: timezone
  'role=kubernetes-master':
    - name: kubeadm
    - name: kubeadm/kubernetes-master
  'role=kubernetes-worker':
    - name: kubeadm/kubernetes-worker
      conditions:
        when:
          condition: eden['kubernetes_cluster_master_count'] > 0
          retry:
            interval: 30s
```

### Tasks

#### Example: Dependencies

```yaml
install vnstat package:
  pkg.installed:
    - name: vnstat
    - refresh: true

# this step will automatically fail if the service (re-)start up failed
start vnstat:
  service.ensure:
    - state: started
    - name: vnstat
    - require:
      - pkg: vnstat
  run_options:
    # cause all nodes to finish this step before continuing
    # be aware that "only" this and dependent tasks are "halted"
    sync_up: true

wait some time:
  time.sleep_rand:
    - time: 15s
    - require:
      - service: vnstat

check if vnstat is producing metrics: # well just as an example
  cmd.run:
    - cmd: vnstat
    - timeout: 5s
  conditions:
    # if this condition is not fullfilled it will automatically fail
    success:
      condition: steps['start vnstat'].State == 'running'
    # this can be used to "block" continuation when `serialize`
    # is used (e.g., load balancer, cluster health)
    continue:
      # `functions['cluster_healthy']()` will call the `cluster_healthy` function
      condition: functions['cluster_healthy']() == true
      retry:
        interval: 15s
        limit: 20
  run_options:
    # only run on two nodes at the same time
    serialize:
      count: 2
      ignoreFailures: true
```

#### Example: Orchestrated sharing of data betweem nodes

**NOTE** Where `data` is meant to be "small", e.g., tokens, certificates.
**NOTE** Also the above example already used "orchestration" tools like `serialize` and/or `sync_up`, but wait there is more.

```yaml
install kubeadm and kubelet package:
  pkg.installed:
    - pkgs:
        - kubelet
        - kubeadm
    - refresh: true

# Such an orchestrated call can also be made in templates
generate kubeadm token:
  cmd.run:
    - cmd: kubeadm token create --tl=10m --description='{{ Server.Spec.FQDN }}'
  run_options:
    target:
      limit: 1
      hosts: 'role=kubernetes-master'

# Other things also possible would be to do something like this:
# The step below would "publish" the /etc/kubernetes/pki/ directory for each node that
# is targteted during this run when the condition(s) are met.
get kubernetes master certs:
  file.content:
    - name: /etc/kubernetes/pki/
    - recursive: true
  run_options:
    target:
      limit: 1
      hosts: 'role=kubernetes-master'
  conditions:
    when:
      condition: 'kubernetes-master' in Server.ObjectMetadata.Labels

# Retrieve the "published" files and put them on the current server.
place kubernetes master certs:
  file.managed:
    - name: /etc/kubernetes/pki/
    - from:
      - file: 'get kubernetes master certs'
  conditions:
    when:
      condition: 'kubernetes-master' in Server.ObjectMetadata.Labels

join node using token:
  cmd.run:
    - cmd: kubeadm --token={{ steps['generate kubeadm token'].StdOut }}
```

### Events

#### "Base" Custom Events File

```yaml
custom_events:
  '*':
    - name: uptime
```

#### Custom Events File

```yaml
# This example should normally be done by a monitoring tool, such as Prometheus.
uptime:
  expression: functions['time_duration_to_unix']('14d') <= variables['uptime']
  name: uptime_over_14d
```

### Events Reaction

```yaml
reactions:
  prometheus:
    alert:
      my-cool-alert:
        reaction: prometheus/alert-runbooks/my-cool-alert
```
